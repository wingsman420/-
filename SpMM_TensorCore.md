# SpMM on Tensor Core
## 适配tensor core(16x16)的重排
### 重排算法
**对于稀疏的LHS矩阵A**

* 对于一个16x16的矩阵，将其分为16个4x4的子矩阵
* 按照上次给出的重排算法先重排一次，将所有稠密子矩阵(稀疏度超过指定稀疏阈值)单独存储为矩阵A~1~后减去，将剩余稀疏部分再以同种方法重排一次 得到A~2~。将AxB分为两部分：
  $$A*B=A_1*B+A_2*B$$
* 增加行重排数组记录元素原来的位置
* 增加元素数量数组以标记每个子块有多少非0元素
  **对于稠密的RHS矩阵B**
* 在A~1~xB部分，对B矩阵进行如下操作：
  1.转置B矩阵
  2.按A~1~方式重排B矩阵
  3.转置B矩阵
* A~2~xB部分同理
  **对于结果矩阵C**
* 将A~1~xB的结果矩阵C~1~和A~2~xB的结果矩阵C~2~还原后相加

***

## 转置策略
**对稠密的RHS矩阵B进行转置：**

* 将B从global memory加载至shared memory
* 将B分成8个8x4的子矩阵，warp对一个8x4的子矩阵进行转置

***

## SpMM在GPU上的具体实现
### 线程分配

* 一个block包含8个warp
* 每个warp包含32个线程
* 将warp分成8组，每组包含4个线程
* 每个线程组计算得到一个8x4的子矩阵
* 分配到每个线程：如下图所示，每个线程进行一个(4\*4)\*(8\*4)的矩阵乘运算，对于**非0元素数量为0**的子矩阵不做运算。4个线程得到的结果累加则得到一个8x4的子矩阵
  ![Alt text](image-1.png)

***

### 数据存储
参考vectorSparse：

* 对于转置后的RHS矩阵B，由于它的低重用率，加载到寄存器中
* 对于重用率高的LHS矩阵，加载至shared memory
